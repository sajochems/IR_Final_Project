{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
      "C:\\Users\\Scott\\AppData\\Local\\Temp\\ipykernel_9392\\2500592727.py:6: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "java is now started automatically with default settings. To force initialisation early, run:\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init()\n"
     ]
    }
   ],
   "source": [
    "import ir_datasets\n",
    "\n",
    "import pyterrier as pt\n",
    "print(pt.__version__)\n",
    "\n",
    "pt.init()\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "from pyterrier.measures import RR, nDCG, MAP, MRR, Recall, Precision\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenericDoc(doc_id='2020338_0', text=\"A small group of politicians believed strongly that the fact that Saddam Hussien remained in power after the first Gulf War was a signal of weakness to the rest of the world, one that invited attacks and terrorism. Shortly after taking power with George Bush in 2000 and after the attack on 9/11, they were able to use the terrorist attacks to justify war with Iraq on this basis and exaggerated threats of the development of weapons of mass destruction. The military strength of the U.S. and the brutality of Saddam's regime led them to imagine that the military and political victory would be relatively easy.\")\n"
     ]
    }
   ],
   "source": [
    "antique = ir_datasets.load(\"antique/train\")\n",
    "print(antique.docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices already exist, skipping creation\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL - Index the data\n",
    "\n",
    "idx_path = Path.cwd() / \"indices\" / \"antique_train\"\n",
    "\n",
    "def antique_gen(limit=500000):\n",
    "    lastdoc = 0\n",
    "    for elem in antique.docs:\n",
    "        if lastdoc >= limit:\n",
    "            break\n",
    "        yield {\n",
    "            \"docno\": elem.doc_id,\n",
    "            \"text\": elem.text,\n",
    "        }\n",
    "        lastdoc += 1\n",
    "\n",
    "max(len(text.encode(\"utf-8\")) for _, text in antique.docs)\n",
    "\n",
    "if not idx_path.exists() or not any(idx_path.iterdir()):\n",
    "    indexer = pt.IterDictIndexer(\n",
    "        str(idx_path),\n",
    "        meta={\n",
    "            \"docno\": 20,\n",
    "            \"text\": 4096,\n",
    "        },\n",
    "        stemmer=\"porter\",\n",
    "        stopwords=\"terrier\",\n",
    "    )\n",
    "\n",
    "    index_ref = indexer.index(antique_gen())\n",
    "else:\n",
    "    print(\"Indices already exist, skipping creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define index paths\n",
    "index_dir_antique = Path.cwd() / \"indices\" / \"antique_train\"\n",
    "# Load the indexes\n",
    "#index_msmarco = pt.IndexFactory.of(str(index_dir_msmarco))\n",
    "index_antique = pt.IndexFactory.of(str(index_dir_antique))\n",
    "\n",
    "# Use BM25 as the baseline retriever\n",
    "#retriever_msmarco = pt.BatchRetrieve(index_msmarco, wmodel=\"BM25\")\n",
    "#retriever_antique = pt.BatchRetrieve(index_antique, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert qrels to DataFrames\n",
    "#qrels_msmarco = pd.DataFrame(msmarco.qrels_iter())\n",
    "qrels_antique = pd.DataFrame(antique.qrels_iter())\n",
    "\n",
    "# Convert queries to DataFrames\n",
    "#queries_msmarco = pd.DataFrame(msmarco.queries_iter())\n",
    "queries_antique = pd.DataFrame(antique.queries_iter())\n",
    "\n",
    "# Rename columns for PyTerrier compatibility\n",
    "#qrels_msmarco.rename(columns={\"query_id\": \"qid\", \"doc_id\": \"docno\", \"relevance\": \"label\"}, inplace=True)\n",
    "qrels_antique.rename(columns={\"query_id\": \"qid\", \"doc_id\": \"docno\", \"relevance\": \"label\"}, inplace=True)\n",
    "\n",
    "#queries_msmarco.rename(columns={\"query_id\": \"qid\", \"text\": \"query\"}, inplace=True)\n",
    "queries_antique.rename(columns={\"query_id\": \"qid\", \"text\": \"query\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "CUDA Available: True\n",
      "Current Device: 0\n",
      "Device Name: NVIDIA GeForce RTX 3060\n",
      "Device Count: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "print(\"Device Count:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Scott\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model imports\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the T5 model\n",
    "MODEL_ID = \"prhegde/t5-query-reformulation-RL\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_ID)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_ID).to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0eb3b33d7db41c092b1cdb36245a28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rewriting queries:   0%|          | 0/2426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to rewrite queries\n",
    "def rewrite_query(query, nsent=1):\n",
    "    input_ids = tokenizer(query, return_tensors=\"pt\").input_ids.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=20, num_beams=1, do_sample=True)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def clean_query(query):\n",
    "    query = query.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"?\", \"\")\n",
    "    query = query.encode(\"ascii\", \"ignore\").decode()\n",
    "    query = re.sub(r\"[\\\"`]\", \"\", query)\n",
    "    query = re.sub(r\"\\s+\", \" \", query).strip()\n",
    "    query = re.sub(r\"[^\\w\\s]\", \"\", query)\n",
    "    return query\n",
    "queries_unchanged = queries_antique[[\"qid\", \"query\"]]#.copy(deep=True)\n",
    "\n",
    "queries_unchanged[\"query\"] = queries_unchanged[\"query\"].apply(clean_query)\n",
    "# queries_antique[\"rewritten_query\"] = queries_antique[\"query\"].apply(rewrite_query).apply(clean_query)\n",
    "\n",
    "queries_antique[\"rewritten_query\"] = [\n",
    "    clean_query(rewrite_query(query))\n",
    "    for query in tqdm(queries_antique[\"query\"], desc=\"rewriting queries\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bm25_antique = pt.terrier.Retriever(index_antique, wmodel=\"BM25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    What causes severe swelling and pain in the knees\n",
      "Name: query, dtype: object\n",
      "Unchanged queries\n",
      "0    causes for severe swelling of the knees\n",
      "Name: query, dtype: object\n",
      "Rewritten queries\n",
      "\n",
      "Results for rewritten queries:\n",
      "+-------------------+---------------------+---------------------+---------------------+\n",
      "|       name        |        RR@10        |       nDCG@20       |         AP          |\n",
      "+-------------------+---------------------+---------------------+---------------------+\n",
      "| TerrierRetr(BM25) | 0.24573764377968843 | 0.12678901410908794 | 0.07606560976303532 |\n",
      "+-------------------+---------------------+---------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "print(queries_unchanged['query'].head(1))\n",
    "\n",
    "\n",
    "print(\"Unchanged queries\")\n",
    "\n",
    "\n",
    "# results_unchanged = pt.Experiment(\n",
    "#     [bm25_antique],\n",
    "#     queries_unchanged[[\"qid\", \"query\"]],  # Use rewritten queries\n",
    "#     qrels_antique,\n",
    "#     eval_metrics=[RR @ 10, nDCG @ 20, MAP],\n",
    "# )\n",
    "queries_antique['query'] = queries_antique['rewritten_query']\n",
    "print(queries_antique['query'].head(1))\n",
    "\n",
    "print(\"Rewritten queries\")\n",
    "\n",
    "results_rewritten = pt.Experiment(\n",
    "    [bm25_antique],\n",
    "    queries_antique[[\"qid\", \"query\"]],  # Use rewritten queries\n",
    "    qrels_antique,\n",
    "    eval_metrics=[RR @ 10, nDCG @ 20, MAP],\n",
    ")\n",
    "\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Optionally, print the results of both experiments using tabulate\n",
    "# print(\"Results for unchanged queries:\")\n",
    "# print(tabulate(results_unchanged, headers='keys', tablefmt='pretty', showindex=False))\n",
    "\n",
    "print(\"\\nResults for rewritten queries:\")\n",
    "print(tabulate(results_rewritten, headers='keys', tablefmt='pretty', showindex=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                     Original Query                                                                 Rewritten Query\n",
      "                                                  What causes severe swelling and pain in the knees                                         causes for severe swelling of the knees\n",
      "                                             why dont they put parachutes underneath airplane seats                                          what should parachutes be on airplanes\n",
      "                                                                  how to clean alloy cylinder heads                                          how to clean a7 ct head cylinder heads\n",
      "                                                                           how do i get them whiter                   what is the best product to use for a person with white hairs\n",
      "                                                                     What is Cloud 9 and 7th Heaven                                      what is the name of cloud 9 and 7th heaven\n",
      "                                                                          How do you like your eggs                                                do dill eggs have a little color\n",
      "                                                                               What is a conscience                              conscience and conscience are both moral and legal\n",
      "                                                                         How do I get college money                  Become a college financer with the help of a real estate agent\n",
      "                                                     how can u tell when a person is tellin u a lie                                       who said something i dont tell u is a lie\n",
      "                                                   How do you transfer voicemail messages onto tape                                can you copy voicemail messages to cassette tape\n",
      "                                                   Why does PAMELA ANDERSON NOT CARE about Children i think christian father was concerned about my daughter while marriedand cried\n",
      "                                 what is the difference between a cigarette and a hand rolled joint                                  what are the advantages of hand rolling joints\n",
      "                                                                             Whats a Taxi Medallion           whats the difference between a taxi medallion and a shuttle medallion\n",
      "                                                                      what is the meaning of nikita                                                      meaning of the word nikita\n",
      "                                                              How do U get rid of corns on the toes                                      can an orthopedist treat corns on the toes\n",
      "Why is it that conservatives attack the critics personally but progressives focus on the principles               which of these views is more likely to be the critic or an expert\n",
      "                                            Why dont you ever see the headline Psychic Wins Lottery                              why dont you see the headline Psychic Wins Lottery\n",
      "                                             How to fade the Scar Mark of face appeared by Stitches                                               does scare cause stitches in face\n",
      "                                                                               What is an Allantois                                                             what is equinus gte\n",
      "                                   How do you determine if something is considered common knowledge                                                do you consider common knowledge\n"
     ]
    }
   ],
   "source": [
    "# Combine the original and rewritten queries side by side\n",
    "comparison_df = pd.DataFrame({\n",
    "    \"Original Query\": queries_unchanged['query'].head(20).values,\n",
    "    \"Rewritten Query\": queries_antique['rewritten_query'].head(20).values\n",
    "})\n",
    "\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
