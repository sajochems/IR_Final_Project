{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
      "C:\\Users\\Scott\\AppData\\Local\\Temp\\ipykernel_11500\\3500952728.py:5: DeprecationWarning: Call to deprecated method pt.init(). Deprecated since version 0.11.0.\n",
      "java is now started automatically with default settings. To force initialisation early, run:\n",
      "pt.java.init() # optional, forces java initialisation\n",
      "  pt.init()\n"
     ]
    }
   ],
   "source": [
    "import ir_datasets\n",
    "import pyterrier as pt\n",
    "print(pt.__version__)\n",
    "\n",
    "pt.init()\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenericDoc(doc_id='2020338_0', text=\"A small group of politicians believed strongly that the fact that Saddam Hussien remained in power after the first Gulf War was a signal of weakness to the rest of the world, one that invited attacks and terrorism. Shortly after taking power with George Bush in 2000 and after the attack on 9/11, they were able to use the terrorist attacks to justify war with Iraq on this basis and exaggerated threats of the development of weapons of mass destruction. The military strength of the U.S. and the brutality of Saddam's regime led them to imagine that the military and political victory would be relatively easy.\")\n"
     ]
    }
   ],
   "source": [
    "antique = ir_datasets.load(\"antique/train\")\n",
    "print(antique.docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962eae5600f24360ad2d06a5139e5a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Antique docs:   0%|          | 0/500000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:09:18.074 [main] WARN org.terrier.structures.indexing.Indexer -- Adding an empty document to the index (730691_1) - further warnings are suppressed\n",
      "14:10:33.362 [main] WARN org.terrier.structures.indexing.Indexer -- Indexed 2224 empty documents\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL - Index the data\n",
    "\n",
    "idx_path = Path.cwd() / \"indices\" / \"antique_train\"\n",
    "\n",
    "def antique_gen(limit=500000):\n",
    "    lastdoc = 0\n",
    "    for elem in tqdm(antique.docs, desc=\"Generating Antique docs\", total=limit):\n",
    "        if lastdoc >= limit:\n",
    "            break\n",
    "        yield {\n",
    "            \"docno\": elem.doc_id,\n",
    "            \"text\": elem.text,\n",
    "        }\n",
    "        lastdoc += 1\n",
    "\n",
    "max(len(text.encode(\"utf-8\")) for _, text in antique.docs)\n",
    "\n",
    "if not idx_path.exists() or not any(idx_path.iterdir()):\n",
    "    indexer = pt.IterDictIndexer(\n",
    "        str(idx_path),\n",
    "        meta={\n",
    "            \"docno\": 20,\n",
    "            \"text\": 4096,\n",
    "        },\n",
    "        stemmer=\"porter\",\n",
    "        stopwords=\"terrier\",\n",
    "    )\n",
    "\n",
    "    index_ref = indexer.index(antique_gen())\n",
    "else:\n",
    "    print(\"Indices already exist, skipping creation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\\AppData\\Local\\Temp\\ipykernel_11500\\2060639876.py:9: DeprecationWarning: Call to deprecated class BatchRetrieve. (use pt.terrier.Retriever() instead) -- Deprecated since version 0.11.0.\n",
      "  retriever_antique = pt.BatchRetrieve(index_antique, wmodel=\"BM25\")\n"
     ]
    }
   ],
   "source": [
    "# Define index paths\n",
    "index_dir_antique = Path.cwd() / \"indices\" / \"antique_train\"\n",
    "# Load the indexes\n",
    "#index_msmarco = pt.IndexFactory.of(str(index_dir_msmarco))\n",
    "index_antique = pt.IndexFactory.of(str(index_dir_antique))\n",
    "\n",
    "# Use BM25 as the baseline retriever\n",
    "#retriever_msmarco = pt.BatchRetrieve(index_msmarco, wmodel=\"BM25\")\n",
    "retriever_antique = pt.BatchRetrieve(index_antique, wmodel=\"BM25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Please confirm you agree to the authors' data usage agreement found at <https://ciir.cs.umass.edu/downloads/Antique/readme.txt>\n",
      "[INFO] [starting] https://ciir.cs.umass.edu/downloads/Antique/antique-train.qrel\n",
      "[INFO] [finished] https://ciir.cs.umass.edu/downloads/Antique/antique-train.qrel: [00:00] [626kB] [1.65MB/s]\n",
      "[INFO] [starting] https://ciir.cs.umass.edu/downloads/Antique/antique-train-queries.txt   \n",
      "[INFO] [finished] https://ciir.cs.umass.edu/downloads/Antique/antique-train-queries.txt: [00:00] [137kB] [620kB/s]\n",
      "                                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert qrels to DataFrames\n",
    "#qrels_msmarco = pd.DataFrame(msmarco.qrels_iter())\n",
    "qrels_antique = pd.DataFrame(antique.qrels_iter())\n",
    "\n",
    "# Convert queries to DataFrames\n",
    "#queries_msmarco = pd.DataFrame(msmarco.queries_iter())\n",
    "queries_antique = pd.DataFrame(antique.queries_iter())\n",
    "\n",
    "# Rename columns for PyTerrier compatibility\n",
    "#qrels_msmarco.rename(columns={\"query_id\": \"qid\", \"doc_id\": \"docno\", \"relevance\": \"label\"}, inplace=True)\n",
    "qrels_antique.rename(columns={\"query_id\": \"qid\", \"doc_id\": \"docno\", \"relevance\": \"label\"}, inplace=True)\n",
    "\n",
    "#queries_msmarco.rename(columns={\"query_id\": \"qid\", \"text\": \"query\"}, inplace=True)\n",
    "queries_antique.rename(columns={\"query_id\": \"qid\", \"text\": \"query\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_query(query):\n",
    "    query = query.encode(\"ascii\", \"ignore\").decode()\n",
    "    query = query.replace(\"'\", \"\").replace('\"', \"\").replace(\"`\", \"\")\n",
    "    query = re.sub(r\"\\s+\", \" \", query).strip()\n",
    "    return query\n",
    "\n",
    "#queries_msmarco[\"query\"] = queries_msmarco[\"query\"].apply(clean_query)\n",
    "queries_antique[\"query\"] = queries_antique[\"query\"].apply(clean_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Scott\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-11): 11 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model imports\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the T5 model\n",
    "MODEL_ID = \"prhegde/t5-query-reformulation-RL\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_ID)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_ID)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\\AppData\\Local\\Temp\\ipykernel_11500\\1477539906.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  queries_unchanged[\"query\"] = queries_unchanged[\"query\"].apply(clean_query)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123031236420438393759b6e25de03b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rewriting queries:   0%|          | 0/2426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to rewrite queries\n",
    "def rewrite_query(query):\n",
    "    input_ids = tokenizer(query, return_tensors=\"pt\").input_ids\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(input_ids, max_length=35, num_beams=1, do_sample=True)\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def clean_query(query):\n",
    "    query = query.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"?\", \"\")\n",
    "    query = query.encode(\"ascii\", \"ignore\").decode()\n",
    "    query = re.sub(r\"[\\\"`]\", \"\", query)\n",
    "    query = query.replace(\"'\", \"\").replace('\"', \"\").replace(\"`\", \"\")\n",
    "    query = re.sub(r\"\\s+\", \" \", query).strip()\n",
    "    query = re.sub(r\"[^\\w\\s]\", \"\", query)\n",
    "    return query\n",
    "\n",
    "queries_unchanged = queries_antique[[\"qid\", \"query\"]]\n",
    "queries_unchanged[\"query\"] = queries_unchanged[\"query\"].apply(clean_query)\n",
    "#queries_antique[\"rewritten_query\"] = queries_antique[\"query\"].apply(rewrite_query).apply(clean_query)\n",
    "\n",
    "#Apply with progress bar\n",
    "queries_antique[\"rewritten_query\"] = [\n",
    "    clean_query(rewrite_query(query))\n",
    "    for query in tqdm(queries_antique[\"query\"], desc=\"rewriting queries\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bm25_antique = pt.terrier.Retriever(index_antique, wmodel=\"BM25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    bicep muscle weakness and pain in knees causes\n",
      "Name: query, dtype: object\n",
      "Unchanged queries\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyterrier\\terrier\\retriever.py:283: UserWarning: Skipping empty query for qid 2041828\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    bicep muscles causes knee pain\n",
      "Name: query, dtype: object\n",
      "Rewritten queries\n",
      "Results for unchanged queries:                 name     RR@10   nDCG@20        AP\n",
      "0  TerrierRetr(BM25)  0.243063  0.121909  0.072937\n",
      "Results for rewritten queries:                 name     RR@10   nDCG@20        AP\n",
      "0  TerrierRetr(BM25)  0.154593  0.080768  0.047341\n"
     ]
    }
   ],
   "source": [
    "print(queries_unchanged['query'].head(1))\n",
    "#print(queries_antique['rewritten_query'].head(1))\n",
    "\n",
    "\n",
    "print(\"Unchanged queries\")\n",
    "\n",
    "\n",
    "results_unchanged = pt.Experiment(\n",
    "    [bm25_antique],\n",
    "    queries_unchanged,  # Use rewritten queries\n",
    "    qrels_antique,\n",
    "    eval_metrics=[RR @ 10, nDCG @ 20, MAP],\n",
    ")\n",
    "queries_antique['query'] = queries_antique['rewritten_query']\n",
    "print(queries_antique['query'].head(1))\n",
    "\n",
    "print(\"Rewritten queries\")\n",
    "\n",
    "results_rewritten = pt.Experiment(\n",
    "    [bm25_antique],\n",
    "    queries_antique[[\"qid\", \"query\"]],  # Use rewritten queries\n",
    "    qrels_antique,\n",
    "    eval_metrics=[RR @ 10, nDCG @ 20, MAP],\n",
    ")\n",
    "\n",
    "# Optionally, print the results of both experiments\n",
    "print(\"Results for unchanged queries:\", results_unchanged)\n",
    "print(\"Results for rewritten queries:\", results_rewritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
